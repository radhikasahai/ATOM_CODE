{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest\n",
    "data_path = '/Users/jayceepang/msse/ATOM_CODE/original_datasets/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2032, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 5)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 5)\n"
     ]
    }
   ],
   "source": [
    "def check_labels(datapath): \n",
    "  \"\"\"a function to check that the labels are indeed what we want (a % binding or % inhibition activiy is \n",
    "  >= 50% for that molecule to be active against that NEK)\"\"\"\n",
    "  assay_pct_dfs = [file for file in os.listdir(datapath) if file.startswith('NEK')]\n",
    "  for file in assay_pct_dfs:\n",
    "    full_file = os.path.join(datapath, file)\n",
    "    df = pd.read_csv(full_file)\n",
    "    \n",
    "    pct_col = [col for col in df.columns if col.startswith('pct_')] \n",
    "    len(pct_col) == 1 \n",
    "    pct_col = pct_col[0]\n",
    "    invalid_labels = df[df['active']!= (df[pct_col]>=50).astype(int)]\n",
    "    if invalid_labels.empty: \n",
    "      # print(f'correct label assignment based on {pct_col} column')\n",
    "      pass\n",
    "    else: \n",
    "      print(f'Error on label assignement.')\n",
    "      print(invalid_labels)\n",
    "    # check for duplicates here \n",
    "    # duplicates = df[df.duplicated()]\n",
    "    print(f'{df.shape}')\n",
    "    # duplicates = df[df.duplicated(subset=['base_rdkit_smiles'])]\n",
    "    # duplicates = df.duplicated()\n",
    "    duplicates = df[df.duplicated(subset=['base_rdkit_smiles'])]\n",
    "    if not duplicates.empty:\n",
    "        print('Duplicate rows found:')\n",
    "        print(duplicates)\n",
    "        df_cleaned = df.drop_duplicates()\n",
    "        print(f'df size original: {df.shape}')\n",
    "        print(f'remove duplicates. {df_cleaned.shape}')\n",
    "    duplicates = df[df.duplicated(subset=['compound_id'])]\n",
    "    if not duplicates.empty:\n",
    "        print('Duplicate rows found:')\n",
    "        print(duplicates)\n",
    "        df_cleaned = df.drop_duplicates()\n",
    "        print(f'df size original: {df.shape}')\n",
    "        print(f'remove duplicates. {df_cleaned.shape}')\n",
    "check_labels(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must specify filename because the 50pct binding and inhibition files differ\n",
    "# to-do: discuss how to do this --> this will create a file that is just this but with column specifying split\n",
    "#       do we want to already integrate a split_uuid like AMPL? \n",
    "#       additionally, we still have to use the splits to create the \"scaled df\" \n",
    "def remove_duplicates(datapath, filename):\n",
    "    df = pd.read_csv(f'{datapath}{filename}')\n",
    "    duplicates = df.duplicated(subset=['base_rdkit_smiles'])\n",
    "    if duplicates.any():\n",
    "        print('Duplicate rows found:')\n",
    "        print(df[duplicates])\n",
    "        df_cleaned = df.drop_duplicates(subset=['base_rdkit_smiles'])\n",
    "        print(f'df size original: {df.shape}')\n",
    "        print(f'Removed duplicates. New df size: {df_cleaned.shape}')\n",
    "    else: \n",
    "        df_cleaned = df\n",
    "    return df_cleaned\n",
    "    \n",
    "def split_data(datapath, filename, train_ratio=.8, test_ratio=0.2): \n",
    "    \"\"\"filename: NEK#_1_uM_min_50_pct_(binding or inhibition).csv\"\"\"\n",
    "    df = remove_duplicates(datapath, filename)\n",
    "\n",
    "    # is this extra/too much and should we just assume what labels coincide with majority and minority? \n",
    "    # determine majority/minority class \n",
    "    #       AMPL takes in 'response column' \n",
    "    class_labels = df['active'].value_counts() \n",
    "    print(class_labels)\n",
    "    if len(class_labels)>1: \n",
    "        majority_class_label =class_labels.idxmax() \n",
    "        majority_num = class_labels.max() \n",
    "        minority_class_label = class_labels.idxmin()\n",
    "        minority_count = class_labels.min()\n",
    "    df_majority = df[df['active']==majority_class_label]\n",
    "    df_minority=df[df['active']==minority_class_label]\n",
    "    # copy to avoid warnings \n",
    "    df_majority = df_majority.copy()\n",
    "    df_minority = df_minority.copy()\n",
    "    n = round(1/test_ratio) # how else can we do this? i think we should keep kfold splits \n",
    "            # 1/.2 = 5 splits \n",
    "    kf = KFold(n_splits=n,shuffle=True, random_state=42)\n",
    "    # majority \n",
    "    for i, (_, v_ind) in enumerate(kf.split(df_majority)):\n",
    "        df_majority.loc[df_majority.index[v_ind], 'fold'] = f\"fold{i+1}\"\n",
    "    # minority \n",
    "    for i, (_, v_ind) in enumerate(kf.split(df_minority)):\n",
    "        df_minority.loc[df_minority.index[v_ind], 'fold'] = f\"fold{i+1}\"\n",
    "    all_fold_df = pd.concat([df_majority,df_minority])\n",
    "    \n",
    "    print(all_fold_df.shape)\n",
    "    print(all_fold_df.active.value_counts())\n",
    "    ## actually, this might be perfect jsut to save as \"split df\" because then \n",
    "    # in the next step of creating a dataset, you can choose what fold you want to be the test set \n",
    "    return all_fold_df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for duplicates and split and save splits\n",
    "This demonstrates how it would be done in a 'tuotrial'. \n",
    "Either put in your datapath and file name one at a time, or find a way to run a for loop if you're doing a buch of datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK9_1_uM_min_50_pct_inhibition.csv\n",
      "NEK9_inhibition\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "0    351\n",
      "1     42\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 6)\n",
      "active\n",
      "0    351\n",
      "1     42\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2_1_uM_min_50_pct_inhibition.csv\n",
      "NEK2_inhibition\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "0    1892\n",
      "1     140\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2032, 6)\n",
      "active\n",
      "0    1892\n",
      "1     140\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK5_1_uM_min_50_pct_binding.csv\n",
      "NEK5_binding\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "0    1140\n",
      "1      97\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237, 6)\n",
      "active\n",
      "0    1140\n",
      "1      97\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK9_1_uM_min_50_pct_binding.csv\n",
      "NEK9_binding\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "0    1348\n",
      "1      61\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 6)\n",
      "active\n",
      "0    1348\n",
      "1      61\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK3_1_uM_min_50_pct_binding.csv\n",
      "NEK3_binding\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "0    1323\n",
      "1      81\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 6)\n",
      "active\n",
      "0    1323\n",
      "1      81\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEK2_1_uM_min_50_pct_binding.csv\n",
      "NEK2_binding\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active\n",
      "0    1351\n",
      "1      57\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import re\\nfrom sklearn.model_selection import KFold\\nimport pandas as pd\\nimport os'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1408, 6)\n",
      "active\n",
      "0    1351\n",
      "1      57\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "assay_pct_dfs = [file for file in os.listdir(data_path) if file.startswith('NEK')]\n",
    "\n",
    "def get_bind_inhib(df_name):\n",
    "    match = re.search(r'_([^_]+)\\.csv$',df_name)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "split_dir = '/Users/jayceepang/msse/ATOM_CODE/datasets/'\n",
    "\n",
    "for i in range(len(assay_pct_dfs)): \n",
    "    bind_inhib = get_bind_inhib(assay_pct_dfs[i])\n",
    "    nek_num = str(assay_pct_dfs[i][3])\n",
    "    print(assay_pct_dfs[i])\n",
    "    NEK_name = f'NEK{nek_num}_{bind_inhib}'\n",
    "    print(NEK_name)\n",
    "    cleaned_split_df = split_data(data_path, assay_pct_dfs[i])\n",
    "\n",
    "    # DO WE DO THIS HERE???  \n",
    "    cleaned_split_df['NEK'] =NEK_name \n",
    "    cleaned_split_df.to_csv(f'{split_dir}{NEK_name}_split.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurization\n",
    "should we do this per dataset? (intend to run this in a for loop?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(train, test): \n",
    "    # file is the split file (folds)\n",
    "    # add code to do standard scaler \n",
    "    # code to scale then concat \n",
    "    scaled_df = pd.concat([train,test])\n",
    "    return scaled_df\n",
    "\n",
    "def featurize(datapath, filename, feat_type, test_fold = 1, n_bits=None): \n",
    "    # if feat_type == 'MOE': \n",
    "        # direct to descriptors files and matchup our split df with the features \n",
    "    # if feat_type == 'MFP' or 'ECFP': \n",
    "        # create MFP feats? \n",
    "        # or should we use ECFP? \n",
    "        # specify bits (is not None)  \n",
    "    # 1. split data based on fold \n",
    "    df = pd.read_csv(datapath+filename) # this is the split.csv \n",
    "    test = df[df['fold']==test_fold]\n",
    "    train=df[df['fold']!=test_fold] \n",
    "    #### HOW DO WE ACCOUNT FOR VALIDATION? ### \n",
    "    # 2. standard scaler \n",
    "    scaled_df = scale_dataset(train,test)\n",
    "    # 3. save scaled_df NO MATTER WHAT.\n",
    "    # ## MAYBE WE SHOULD SAVE IT IN THE SCALE DF FUNCTION?  ## \n",
    "    # 4. perform featurization \n",
    "    # 5. save datasets \n",
    "    # 6. possibly, call function to prep for training (save trainX.csv, train_y.csv, testX.csv, test_y.csv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'm checking the scaled_descriptors files because I knew there were duplicates in these files \n",
    "# desc_dir = '/Users/jayceepang/msse/ATOM_CODE/original_datasets/scaled_descriptors/'\n",
    "# desc_dfs = [file for file in os.listdir(desc_dir) if file.startswith('NEK')]\n",
    "\n",
    "# print(desc_dfs)\n",
    "# for i in range(len(desc_dfs)): \n",
    "#     split_data(desc_dir, desc_dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1904+140=2044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['NEK', 'compound_id', 'base_rdkit_smiles','subset', 'active'] \n",
    "def over_sampling(data_path,filename, sampling, NEK):\n",
    "    \"\"\"Oversample the datasetes using the SMOTE or ADASYN\n",
    "    Keeps the feature names and id cols\n",
    "    file_name (full/absolute path): use the scaled dataframe we just created above 'NEK#_(binding/inhibition)_(MOE/MFP)_none_scaled_df.csv'\n",
    "    sampling (str): 'SMOTE' or 'ADASYN'\n",
    "    returns: oversampled dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_path+filename) # this is the already scaled ver\n",
    "    feat_cols = list(set(list(df.columns))-set(id_cols))\n",
    "    \n",
    "    # train and test \n",
    "    train = df[df['subset']=='train'] \n",
    "    test =df[df['subset']=='test'] \n",
    "\n",
    "    # separate just id cols\n",
    "    just_ids = ['NEK', 'compound_id', 'base_rdkit_smiles','subset']\n",
    "    train_just_ids = train[just_ids]\n",
    "    test_just_ids = test[just_ids]\n",
    "\n",
    "    # just feats and 'active'\n",
    "    trainX = train[feat_cols]\n",
    "    testX = test[feat_cols]\n",
    "    \n",
    "    trainy = train['active']\n",
    "    testy = test['active']\n",
    "    \n",
    "    if sampling == 'ADASYN':\n",
    "        oversample = ADASYN(random_state=42)\n",
    "    else: \n",
    "        oversample = SMOTE(random_state=42)\n",
    "\n",
    "    \n",
    "    trainX_temp, trainy_temp = oversample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "    print(f'train after {sampling}: {trainX_temp.shape}')\n",
    "    \n",
    "    trainX_resamp = pd.DataFrame(trainX_temp, columns=feat_cols)\n",
    "    trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "\n",
    "    num_real = len(train)\n",
    "    num_synthetic = len(trainX_resamp)-num_real\n",
    "    synthetic_ids = pd.DataFrame({'NEK': [NEK] * num_synthetic,\n",
    "        'compound_id': [f'synethic_{sampling}_{i}' for i in range(num_synthetic)],\n",
    "        'base_rdkit_smiles': [f'synethic_{sampling}'] * num_synthetic,\n",
    "        'subset': ['train']*num_synthetic}) # ,'active':[1]*num_synthetic}\n",
    "\n",
    "    real_ids = train_just_ids.reset_index(drop=True)\n",
    "    combined_ids = pd.concat([real_ids,synthetic_ids], ignore_index=True)\n",
    "    \n",
    "    train_resamp = pd.concat([combined_ids, trainX_resamp, trainy_resamp[['active']]], axis=1)\n",
    "\n",
    "    print(train_resamp.columns[train_resamp.columns.duplicated()])\n",
    "    test_df_final = pd.concat([test_just_ids.reset_index(drop=True),\n",
    "                               testX.reset_index(drop=True), testy.reset_index(drop=True)],axis=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    # test_df_final['subset'] = 'test'\n",
    "    # train_resamp = train_resamp.reindex(columns=df.columns)\n",
    "    # test_df_final = test_df_final.reindex(columns=df.columns)\n",
    "    \n",
    "    \n",
    "    final_df = pd.concat([train_resamp, test_df_final]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return final_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['NEK', 'compound_id', 'base_rdkit_smiles','subset', 'active'] \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "def undersampler(path,filename,NEK): \n",
    "    df = pd.read_csv(path+filename) # this is the already scaled ver\n",
    "    feat_cols = list(set(list(df.columns))-set(id_cols))\n",
    "    \n",
    "    \n",
    "    # train and test \n",
    "    train = df[df['subset']=='train'] \n",
    "    test =df[df['subset']=='test'] \n",
    "\n",
    "    # separate just id cols\n",
    "    just_ids = ['NEK', 'compound_id', 'base_rdkit_smiles','subset']\n",
    "    train_just_ids = train[just_ids]\n",
    "    test_just_ids = test[just_ids]\n",
    "\n",
    "    # just feats and 'active'\n",
    "    trainX = train[feat_cols]\n",
    "    testX = test[feat_cols]\n",
    "    \n",
    "    trainy = train['active']\n",
    "    testy = test['active']\n",
    "    \n",
    "    undersample = RandomUnderSampler(random_state=42)\n",
    "    \n",
    "    trainX_temp, trainy_temp = undersample.fit_resample(trainX.to_numpy(), trainy.to_numpy().reshape(-1))\n",
    "    \n",
    "    trainX_resamp = pd.DataFrame(trainX_temp, columns=feat_cols)\n",
    "    trainy_resamp = pd.DataFrame(trainy_temp, columns=['active'])\n",
    "    \n",
    "    train_ids_resamp = train_just_ids.iloc[trainX_resamp.index].reset_index(drop=True)\n",
    "    train_resamp= pd.concat([train_ids_resamp, trainX_resamp,trainy_resamp], axis=1)\n",
    "    train_resamp['subset'] = 'train'\n",
    "\n",
    "    test_df_final = pd.concat([test_just_ids.reset_index(drop=True),testX.reset_index(drop=True),testy.reset_index(drop=True)],axis=1)\n",
    "    test_df_final['subset'] = 'test'\n",
    "    final_df = pd.concat([train_resamp,test_df_final]).reset_index(drop=True)\n",
    "    \n",
    "    return final_df[list(df.columns)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# over_sampling(featurized_filepath, 'NEK2_binding_MFP_none_scaled.csv', \"SMOTE\", \"NEK2_binding\")\n",
    "testing_jaycee =undersampler('/Users/jayceepang/msse/capstone/atom2024/atom2024/notebooks/paper/datasets/80train_20test/featurized/', 'NEK2_binding_MFP_none.csv',\"NEK2_binding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEK</th>\n",
       "      <th>compound_id</th>\n",
       "      <th>base_rdkit_smiles</th>\n",
       "      <th>subset</th>\n",
       "      <th>active</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_10</td>\n",
       "      <td>CCS(=O)(=O)N1CC(CC#N)(n2cc(-c3ncnc4[nH]ccc34)c...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_100</td>\n",
       "      <td>C[C@@H](Oc1cc(C(=O)Nc2ccc(C(=O)N3CCN(C)CC3)cc2...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_1003</td>\n",
       "      <td>CC1(O)CC(c2nc(-c3ccc4ccc(-c5ccccc5)nc4c3)c3c(N...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_101</td>\n",
       "      <td>COCC(=O)NC/C=C/c1ccc2ncnc(Nc3ccc(Oc4ccc(C)nc4)...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_102</td>\n",
       "      <td>COC(=O)c1ccc2c(c1)NC(=O)/C2=C(\\Nc1ccc(N(C)C(=O...</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_2667</td>\n",
       "      <td>C[C@@H](Oc1cc(-n2cnc3cc(-c4ccnc(NCCS(C)(=O)=O)...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_2696</td>\n",
       "      <td>COc1cccc(C2=C(Nc3cc(Cl)c(O)c(Cl)c3)C(=O)NC2=O)c1</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_2840</td>\n",
       "      <td>COc1cc(Nc2nccc(-c3c(-c4cccc(NC(=O)c5c(F)cccc5F...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_2863</td>\n",
       "      <td>CCN(CC)CCOc1ccc(Nc2ncc3cc(-c4c(Cl)cccc4Cl)c(=O...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>NEK2_binding</td>\n",
       "      <td>kdb_980</td>\n",
       "      <td>Cc1cnc(-c2cnc(NCCNc3ccc(C#N)cn3)nc2-c2ccc(Cl)c...</td>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 2053 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              NEK compound_id  \\\n",
       "0    NEK2_binding      kdb_10   \n",
       "1    NEK2_binding     kdb_100   \n",
       "2    NEK2_binding    kdb_1003   \n",
       "3    NEK2_binding     kdb_101   \n",
       "4    NEK2_binding     kdb_102   \n",
       "..            ...         ...   \n",
       "368  NEK2_binding    kdb_2667   \n",
       "369  NEK2_binding    kdb_2696   \n",
       "370  NEK2_binding    kdb_2840   \n",
       "371  NEK2_binding    kdb_2863   \n",
       "372  NEK2_binding     kdb_980   \n",
       "\n",
       "                                     base_rdkit_smiles subset  active  0  1  \\\n",
       "0    CCS(=O)(=O)N1CC(CC#N)(n2cc(-c3ncnc4[nH]ccc34)c...  train       0  0  0   \n",
       "1    C[C@@H](Oc1cc(C(=O)Nc2ccc(C(=O)N3CCN(C)CC3)cc2...  train       0  0  0   \n",
       "2    CC1(O)CC(c2nc(-c3ccc4ccc(-c5ccccc5)nc4c3)c3c(N...  train       0  0  0   \n",
       "3    COCC(=O)NC/C=C/c1ccc2ncnc(Nc3ccc(Oc4ccc(C)nc4)...  train       0  0  0   \n",
       "4    COC(=O)c1ccc2c(c1)NC(=O)/C2=C(\\Nc1ccc(N(C)C(=O...  train       0  0  1   \n",
       "..                                                 ...    ...     ... .. ..   \n",
       "368  C[C@@H](Oc1cc(-n2cnc3cc(-c4ccnc(NCCS(C)(=O)=O)...   test       1  0  1   \n",
       "369   COc1cccc(C2=C(Nc3cc(Cl)c(O)c(Cl)c3)C(=O)NC2=O)c1   test       1  0  0   \n",
       "370  COc1cc(Nc2nccc(-c3c(-c4cccc(NC(=O)c5c(F)cccc5F...   test       1  0  0   \n",
       "371  CCN(CC)CCOc1ccc(Nc2ncc3cc(-c4c(Cl)cccc4Cl)c(=O...   test       1  0  0   \n",
       "372  Cc1cnc(-c2cnc(NCCNc3ccc(C#N)cn3)nc2-c2ccc(Cl)c...   test       1  0  0   \n",
       "\n",
       "     2  3  4  ...  2038  2039  2040  2041  2042  2043  2044  2045  2046  2047  \n",
       "0    0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "1    0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "2    0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "3    0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "4    0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "..  .. .. ..  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "368  0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "369  0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "370  0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "371  0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "372  0  0  0  ...     0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[373 rows x 2053 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_jaycee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['NEK', 'compound_id', 'base_rdkit_smiles','subset', 'active'] ### MAKE SUREFOLD IS NOT IN THIS \n",
    "def create_arrays(filepath, root,save_path, printout=True): \n",
    "    df = pd.read_csv(file_path+df_filename)\n",
    "    train = df[df['subset']=='train']\n",
    "    test=df[df['subset']=='test']\n",
    "    feat_cols = list(set(list(df.columns))-set(id_cols))\n",
    "    \n",
    "    train_y = train['active'].to_numpy().reshape(-1)\n",
    "    test_y=test['active'].to_numpy().reshape(-1)\n",
    "\n",
    "    \n",
    "    trainX = train.drop(columns=id_cols).to_numpy()\n",
    "    testX = test.drop(columns=id_cols).to_numpy()\n",
    "    if printout: \n",
    "        print(f'train X shape: {trainX.shape}, y: {train_y.shape}, test X: {testX.shape}, y:{test_y.shape}')\n",
    "    if save_path is not None: \n",
    "        trainX = pd.DataFrame(trainX)\n",
    "        trainX.to_csv(file_path+root+'_trainX.csv', index=False)\n",
    "   \n",
    "        trainy_df = pd.DataFrame(train_y)\n",
    "        trainy_df.to_csv(file_path+root+'_train_y.csv', index=False) \n",
    "\n",
    "        testX = pd.DataFrame(testX)\n",
    "        testX.to_csv(file_path+root+'_testX.csv', index=False)\n",
    "\n",
    "        testy_df = pd.DataFrame(test_y)\n",
    "        testy_df.to_csv(file_path+root+'_test_y.csv', index=False) \n",
    "        \n",
    "    return trainX, train_y, testX, test_y\n",
    "\n",
    "def get_arrays(file_path, df_filename,printout=False):\n",
    "   # MAKE SURE FOLD IS NOT IN THIS ###### \n",
    "    df = pd.read_csv(file_path+df_filename)\n",
    "    feat_cols = list(set(list(df.columns))-set(id_cols))\n",
    "    train_df= df[df['subset']=='train']\n",
    "    test_df = df[df['subset']=='test']\n",
    "    train_y = train_df['active'].to_numpy().reshape(-1)\n",
    "    test_y=test_df['active'].to_numpy().reshape(-1)\n",
    "    train_x_df = train_df.drop(columns='active')\n",
    "\n",
    "  \n",
    "    test_x_df = test_df.drop(columns='active')\n",
    "    \n",
    "    train_x_df = train_df[feat_cols]\n",
    "    test_x_df = test_df[feat_cols]\n",
    "\n",
    "    if printout: \n",
    "        print(f'train X shape: {trainX.shape}, y: {train_y.shape}, test X: {testX.shape}, y:{test_y.shape}')\n",
    "\n",
    "    ### OR read in the data \n",
    "    trainX = pd.read_csv(need to put in file name_trainX.csv')\n",
    "    ... \n",
    "        \n",
    "    return trainX, train_y, testX, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for nek in neks: \n",
    "    for feat in feats: \n",
    "        for samp in ['UNDER', 'SMOTE', 'ADASYN']:\n",
    "            og_df_name = f'{nek}_{feat}_none_scaled.csv'\n",
    "            if samp == 'UNDER': \n",
    "                sampled_df = undersampler(filepath,filename) \n",
    "            else: \n",
    "                sampled_df=oversampler(filepath,filename, samp, nek) \n",
    "            sampled_df.to_csv(f'{save_dir OR same filepath}{nek}_{feat}_{samp}.csv',index=False)\n",
    "            _, _,_,_=create_arrays(filepath, og_df_name, save_dir OR same filepath) \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplings =['none_scaled','UNDER','SMOTE','ADASYN'] \n",
    "for nek in neks: \n",
    "    for feat in feats: \n",
    "        for samp in samplings:\n",
    "            root_name = f'{nek}_{feat}_{samp}'\n",
    "            df = pd.read_csv(fileapth+root_name+'.csv')\n",
    "            trainX, train_y, testX, test_y=get_arrays(filepath,root_name+'.csv')\n",
    "            for rf in RF_types: \n",
    "                \n",
    "                model = rf_models(trainX, trainy, testX, testy, rf, {})  # make sure dict and doesn't go to default RF version\n",
    "                model_name = f'{nek}_{feat}_{samp}_{rf}'\n",
    "                print(model_name) \n",
    "                with open(f'{model_pickle_dir}{model_name}.pkl', 'wb') as f: \n",
    "                    pickle.dump(model, f) \n",
    "                # add cm and other metrics to this function \n",
    "                train_df = gather_rf_results(model, trainX, trainy)\n",
    "                test_df = gather_rf_results(model, testX, testy)\n",
    "                train_df['subset'] = 'train' \n",
    "                test_df['subset'] = 'test' \n",
    "                \n",
    "                for this_df in [train_df,test_df]: \n",
    "                    this_df['model'] = model_name\n",
    "                    this_df= add_cm(this_df)\n",
    "                    this_df['NEK'] =nek\n",
    "                    this_df['feat_type'] = feat\n",
    "                    this_df['strategy'] = samp\n",
    "                    this_df['RF_type'] = rf\n",
    "                train_df.to_csv(f'{results_dir}{model_name}_train.csv',index=False) \n",
    "                test_df.to_csv(f'{results_dir}{model_name}_test.csv',index=False) \n",
    "                    \n",
    "                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5 \n",
    "# import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# y = np.array([0, 0, 1, 1])\n",
    "# skf = StratifiedKFold(n_splits=2)\n",
    "# skf.get_n_splits(X, y)\n",
    "# print(skf)\n",
    "# for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "#     print(f\"Fold {i}:\")\n",
    "#     print(f\"  Train: index={train_index}\")\n",
    "#     print(f\"  Test:  index={test_index}\")\n",
    "# skf = StratifiedKFold(n_splits=k)\n",
    "# skf.get_n_splits(X, y)\n",
    "for nek in neks: \n",
    "    for feat in feats: \n",
    "        for samp in samplings:\n",
    "            filename = f'{nek}_{feat}_{samp}'\n",
    "            # call create folds \n",
    "            folded_df = create_folds(datapath, filename, k)\n",
    "            # fold_dataframes = []\n",
    "                for fold in folded_df['fold'].unique():\n",
    "                    train_df = folded_df [folded_df ['fold'] != fold].copy()\n",
    "                    val_df = folded_df [folded_df ['fold'] == fold].copy()\n",
    "                    \n",
    "                    train_df['subset'] = 'train'\n",
    "                    val_df['subset'] = 'validation' # or should we jsut say 'test' \n",
    "            \n",
    "                    fold_df = pd.concat([train_df, val_df])\n",
    "                    # fold_dataframes.append(fold_df)\n",
    "                    fold_df.to_csv(f'{FOLDdatapath}{filename}_{fold}.csv', index=False)\n",
    "            \n",
    "            \n",
    "                # combined_folds_df = pd.concat(fold_dataframes, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
